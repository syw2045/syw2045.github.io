---
title: "[DL] CS231n Lecture 3 : Loss functions and Optimization"

categories:
  - DL
tags:
  - [DL, CV]

toc: true
toc_sticky: true

date: 2025-02-15
last_modified_at: 2025-02-15
---
TODO

- Define a loss function that quantifies our unhappiness with the scores across the training data.
- Come up with a way of efficiently finding the parameters that minimize the loss function. (Optimization)

# 1. Loss function

좋은 W를 구하는 방법을 배우기 전에, 먼저 어떤 W가 좋은지 나쁜지를 정의해야 한다. 또 W가 좋다면 얼마나 좋은지 나쁘다면 얼마나 나쁜지를 알아야 한다. W를 입력으로 받아 클래스별 점수를 확인하여 얼마나 나쁜지를 정량적으로 나타내는 함수가 바로 손실 함수(Loss function)이다.

![Image](https://github.com/user-attachments/assets/38f18d8e-68e8-464b-8a70-1d66712d30db)

# 2. SVM Loss

SVM Loss는 다음과 같은 형태를 갖는다.

![Image](https://github.com/user-attachments/assets/bad67c37-3036-4c86-a406-a24a9b0a8e67)

s : 분류기의 출력으로 나온 예측된 스코어

$$s_j$$ : 오답 레이블, $$s_{y_i}$$ : 정답 레이블, 1 : safety margin (임의의 값)

위 수식은 if ~ then으로도 나타낼 수 있다. 위 값을 계산한 것이 손실함수가 되고 정답 레이블 수가 더 크다면 손실함수는 0이다.

Multiclass SVM loss 그래프 형태 때문에 Hinge Loss라고도 한다.

![Image](https://github.com/user-attachments/assets/0288f136-a4c7-407d-ac28-6d0c569a244a)

Y축은 Loss를 나타내고, 0이 된 이후에도 safety margin을 넘어설 때 까지 더 줄어든다.

Loss가 0이 됐다는 것은 클래스를 잘 분류했다는 뜻이다.

즉, Loss는 정답 스코어가 다른 스코어보다 높으면 좋다는 뜻이다.

예를 들어 고양이의 손실 함수를 계산해보면 다음과 같다.

![Image](https://github.com/user-attachments/assets/40f4e1f8-6ae5-441f-abb5-b13eb77a064b)

j $$\neq$$ $$y_i$$ 인 경우의 합이므로 고양이의 경우 자동차와 개구리의 Loss만 계산한다.

여기서 계산된 2.9라는 값은 이 분류기의 이미지 분류 성능의 척도가 된다. 마찬가지로 자동차와 개구리도 계산을 해보면 각각 0과 12.9라는 값이 나온다.

![Image](https://github.com/user-attachments/assets/b2b4ecd3-802a-49ad-b0b5-d2c1a0b82e3e)

최종적으로 이 분류기의 Loss function은 각 이미지의 Loss의 합에 class의 수인 3으로 나눠 계산한다.

이것은 분류기가 5.27만큼 이미지를 안좋게 분류한다는 정량적 지표가 되는 것이다.

## 2.1 Questions

Q. safety margin을 정하는 기준

A. 임의로 선택한 숫자같아 보이긴 하지만, 사실 손실함수의 스코어가 정확히 몇인지는 신경쓰지 않는다. 중요한 것은 여러 스코어 간의 상대적인 차이이다.

saftey margin 1이라는 값은 W의 스케일 변화에 의해 상쇄될수도 있다.

Loss function에 대한 직관적인 이해를 돕기 위한 질문

> Q1: What happens to loss if car scores change a bit?

⇒ Loss는 그대로 0이다.
SVM Loss의 경우 정답과 오답의 스코어의 차이를 계산하는데, 조금 변하더라도 차이가 역전되지는 않기 때문에. 

> Q2: what is the min/max possible loss?

⇒ 최댓값 : 0, 최대값 : $$\infty$$

hinge Loss의 형태를 보면 Loss가 무한대로 커질 수 있다는 것을 알 수있다.

> Q3: At initialization W is small so all s ≈ 0. What is the loss?

⇒ Loss = Class - 1 (Class 가 10개라면 loss = 9)

s값이 서로 비슷하다면 safety margin인 1이 나올 것이고 정답이 아닌 class에 대해서 순회를 하니 class-1를 Loss function으로 얻을 것이다.

이것을 활용해 Debugging 방법으로 사용할 수 있다.
W를 initialize 한 후 학습을 시작할 때 Loss = Class - 1가 아니라면 버그가 있는 것으로 판단하고 수정을 해야한다.

> Q4: What if the sum was over all classes? (including $$j = y_i$$)

⇒ 계산된 Loss에 1이 더해진다.

이렇게 하지 않는 이유는 최소 Loss가 0이 되게 하기 위함 (관례상, 해석을 용이하게 하려고)

> Q5: What if we used mean instead of sum?

⇒ 변함 없다.

평균을 구한다는 것은 클래스 수를 알기 때문에 그냥 손실 함수를 리스케일한 것이고 스코어 값이 정확히 몇인지는 중요하지 않다고 했다.

> Q6: What if we used square term in loss function?

⇒ 변화가 있다.

Loss function간의 좋고 나쁜 trade-off를 비선형적인 방식으로 바꾸기 때문이다. 이렇게 되면 손실 함수의 계산 자체가 바뀌게 된다.

그렇다면 제곱 항을 왜 고려해야하는 것일까?

앞서 말했듯 손실 함수의 목적은 좋고 나쁨을 정량화 한다는 것이다. 즉, 제곱 연산을 하면 나쁜것은 제곱되게 안좋다는 것을 알 수 있다.

> Q7: Suppose that we found a W such that L = 0. is this W unique?

즉, Loss가 0이 되는 원하던 W를 구했을 때, 이 W는 유의미한 값일까? 2W의 값도 Loss는 0이된다. 

![Image](https://github.com/user-attachments/assets/218ba72a-393f-4e0b-bb47-224b410c5fae)

손실 함수라는 것이 분류기에게 어떤 W를 찾고 있고, 어떤 W에 신경쓰고 있는지를 말해주는 것이라면 다양한 W중에서 Loss가 0인것을 선택하는 것은 모순이 있다. 왜냐하면 지금 계산한 것은 학습 데이터에 대해서 만 얼마나 정확하게 분류하는지 이기 때문이다. 

# 3. Regularization

![Image](https://github.com/user-attachments/assets/79fab7ab-11ac-44f4-8e30-10bddaed387d)

이 수식은 학습 데이터에 대해 얼마나 정확하게 분류하는지 만을 알 수 있다. 하지만 진짜 목적은 학습데이터에 대한 분류 성능이 아닌 테스트 데이터 분류 성능이다.

그러므로 분류기에게 학습데이터의 Loss에 대해서만 신경을 쓰라고 하면 안좋은 결과가 나올 것이다.

![Image](https://github.com/user-attachments/assets/31ca9215-fb6f-4432-9e31-dcfbe5db3bb6)

학습데이터를 정확하게 분류하는 파란색 곡선은 테스트데이터인 초록색이 추가되면 완전히 틀린 경우가 된다. 사실은 초록색 직선을 원했던 것이다. 이러한 문제를 해결하는 방식으로 손실 함수에 항을 하나 추가한다.

![Image](https://github.com/user-attachments/assets/e057734f-1150-4b6b-8eb6-9d086f4a9843)

Data Loss에서는 학습데이터에 fit하게 만들고, Regularization을 추가해 모델이 좀 더 단순한 W를 선택하도록 한다. 여기서 단순하다라는 것은 해결해야 하는 문제나 모델에 따라 조금씩 달라진다.

Regularization term은 모델이 데이터에 fit할 때 저차 다항식을 더 선호하도록 하게 한다.

Regularization의 두가지 역할

1. 모델이 더 복잡해지지 못하도록 하는 것.
2. 모델에 soft penalty를 추가하는 것
    - 모델은 여전히 더 복잡한 모델이 될 가능성이 있는 것, 하지만 soft penalty를 통해 복잡한 모델을 선택하면 이 penalty를 감수해야한다고 말하는 것

## 3.1 Regularization의 종류

![Image](https://github.com/user-attachments/assets/34a48a79-b1c7-4eac-82cc-fac7b11b9902)

L2 Regularization은 가중치 행렬W에 대한 Euclidean Norm에 패널티를 주는 것이다.

(Squared norm이라고도 함, 또는 미분을 깔끔하게 하기 위해 1/2 *  Squared norm을 사용하기도 함)

L1 Regularization 행렬 W가 희소행렬이 되도록 한다.

Regularization은 모델이 학습데이터셋에 완벽히 fit하지 못하도록 모델의 complexity에 패널티를 부여하는 방법이다.

> L2 regularization

![Image](https://github.com/user-attachments/assets/ad2cd2c2-2417-416d-a845-17b46d90c5d3)

x와 w1, w2를 각각 내적했을 때 모두 1이라는 값을 갖는다. 이때 L2 Regularization은 $$w_2$$가 더 norm이 작기 때문에 선호한다. 그러므로 L2 Regularization은 분류기의 complexity를 상대적으로 W1과 W2중 어떤 것이 더 coarse한지를 측정한다.

Linear classification에서 W가 의미하는 것은 value vector x가 얼마나 output class와 닮았는가 이다. 그러므로 L2 regularization는 W를 가능한 spread out해서 모든 input feature x 들을 고려하기를 원함 (diffuse over everything) 동일한 Score라면 최대한 spread out 된것을 선호한다.

L1 Regularization의 경우는 반대이다. 즉 W2보다는 W1을 더 선호하게 된다. 이경우에는 complexity를 다르게 정의한다. 가중치 W에 0의 개수에 따라 모델의 complexity를 측정한다.

L1 : 일반적으로 Sparse한 solutuons를 선호한다.

# 4. Softmax Classifier (Multinomial Logistic Regression)

multi-class SVM의 경우 스코어 자체에는 크게 신경쓰지 않았다. 단지 정답 클래스가 오답 클래스들 보다 더 높은 스코어를 내기만을 원했다. 하지만 Multinomial Logistic Regression의 손실함수는 스코어 자체에 추가적인 의미를 부여한다.

![Image](https://github.com/user-attachments/assets/8f120ee9-69fd-4bc7-a8f5-49384f91375a)

![Image](https://github.com/user-attachments/assets/ef92e7db-155c-4b1f-b254-1abec02b6e76)

스코어에 지수를 취해서 양수로 만들고, normalize를 해 해당 클래스일 확률로 계산한다.
확률이기 때문에 0에서 1사이의 값이고, 합이 1이다.

이 분류기에서 원하는 것은 정답 클래스에 해당하는 클래스의 확률이 1에 가깝게 계산되는 것이다. 그렇게 되면 Loss는 -log(정답 클래스 확률) 이다.

log를 쓰는 이유는 log는 단조증가함수라서 log를 최대화시키는 것이 그냥 확률값을 최대화 시키는 것보다 쉽다. 그리고 손실함수는 얼마나 나쁜지를 평가하는 것이기 떄문에 -를 붙인다.

![Image](https://github.com/user-attachments/assets/8b3198a4-13df-49a8-a12b-35d304ff1e35)

요약을 하자면 스코어가 있으면, softmax를 거치고 나온 확률 값에 -log를 추가하면 된다.

## 4.1 Questions

> Q1: What is the min/max possible loss $$L_i$$?

⇒ 최소 : 0, 최대 $$ \infty$$

확률 1(정답)과 0(그외)를 얻으려면, 정답 클래스의 스코어는 $$+ \infty$$가 되어야 하고, 나머지는 $$- \infty $$이 되어야 한다. 하지만 컴퓨터는 무한대 계산을 잘 못하기 때문에 Loss가 0인 경우는 절대 없을 것이다.

> Q2: Usually at initialization W is small so all s ≈ 0. What is the loss?

⇒ log(c)가 된다.

SVM에서 사용했던 디버깅 방법처럼 마찬가지로 초기 값이 log(c)가 아니라면 문제가 있는 것이다.

## 4.2 Softmax vs SVM

![Image](https://github.com/user-attachments/assets/9d02be4d-b9ce-45fa-9c7c-77a6bf1806eb)

Linear classification의 설정은 둘다 같은 조건이다.

행렬 W와 입력을 못하는 것은 둘다 같다. 하지만 두 손실함수의 차이점은 얼마나 나쁜지를 측정하기 위해 스코어를 해석하는 방식이 다르다는 점이다.

SVM에서는 정답 스코어와, 오답 스코어 간의 margins을 신경 썼다.

Softmax에서는 확률을 구해서 -log에 신경쓴다.

Q: Suppose I take a datapoint and I jiggle a bit (changing its score slightly). What happens to the loss in both cases?

앞서 SVM에서는 자동차의 점수는 다른 클래스보다 월등히 높았어서 스코어를 살짝 조정해도 큰 변화가 없었다. 하지만 Softmax에서는 정답 스코어가 충분히 높고, 다른 클래스 스코어가 충분히 낮은 상태에서도 최대한 정답 클래스의 확률을 높이려고 정답 클래스는 무한대로, 그 외의 클래스는 음의 무한대로 보내려고 할 것이다.

SVM의 경우 일정 margins을 넘기만 하면 더이상 성능 개선에 신경쓰지 않는다. 하지만 softmax는 더 좋게 성능을 높이려고 한다.

# 5. Summary

![Image](https://github.com/user-attachments/assets/f437673d-c18d-4529-acd2-74d535cf52fe)

입력 x로부터 스코어를 얻기 위해 Linear classifier를 사용한다.

Softmax, SVM Loss와 같은 손실함수를 사용해, 모델의 예측값이 정답에 비해 얼마나 안좋은지 측정한다. 그리고 모델의 complexity와 simple을 통제하기 위해 손실 함수에 regularization term을 추가한다.

이 모든 것을 합쳐서 최종 손실 함수가 최소가 되게 하는 가중치 행렬이자 파라미터인 W을 구하게 된다.

---

# 6. Optimization

> Random sampling

임의의 샘플링한 W들을 엄청 많이 모아두고 Loss를 계산해서 어떤 W가 좋은지를 살펴보는 것, 성능이 좋지 않아 절대 사용할일없고 그저 이런 방법도 있다.

> Local geometry

현재 있는 곳에서 낮은 방향으로 조금씩 이동하는 것

1차원 공간에서 경사(Slope)는 어떤 함수에 대한 미분값이다.

이것은 스칼라가 아니라 벡터이다 그러므로 다변수 함수로 확장이 가능하다. 다변수인 상황에서의 미분으로 일반화 시켜보면 gradient이고, 이것은 벡터 x의 각 요소 편도함수들의 집합이다.

입력이 3개면 gradient도 3개가 나온다. gradient의 각 요소가 알려주는 것은 그쪽으로 이동할 때 함수 f의 경사가 어떤지 알 수 있다. gradient가 가장 큰 것은 경사가 가장 가파른 곳이고, gradient 반대 방향은 가장 많이 내려갈 수 있는 방향이다.

특정 방향에서 얼마나 가파른지 알고싶으면 그 방향의 유닛 벡터와 gradient 벡터를 내적하면 알 수 있다.

gradient는 함수의 어떤 지점에서 선형 1차 근사함수를 알려주기 때문에 매우 중요하다.

gradient의 각요소가 말해주는 것은 그쪽 방향으로 아주 조금 이동했을 때의 Loss 변화량이다.

이것을 간단하게 finite difference approximation으로 계산할 수 있다.

![Image](https://github.com/user-attachments/assets/7fe24f63-4d04-401c-8552-59dd597f466b){: width="50%", height="50%"}

벡터의 첫번째 요소에 0.0001만큼 이동을 하고 Loss를 계산했더니 감소한 것을 볼 수있다. 이것을 통해 gradient 근사치를 구할 수 있다. 이것을 두 번째 요소에도 반복해서 계산한다. 계속 반복

이 방식은 모두 계산을 해야하기 떄문에 시간이 너무 오래걸린다.

![Image](https://github.com/user-attachments/assets/2289fa76-71eb-48b9-8bb1-e42d31c25099){: width="50%", height="50%"}

실제로 사용을 할 때는 Numerical gradient가 아니라, Analytic gradient 방식을 사용한다. 몇개의 값을 통해 gradient dW를 구하는 식을 구하고 전부 계산해버린다.

하지만 이런 Numerical gradient도 디버깅 툴로 사용할 수 있다. 내가 작성한 미분 코드가 제대로 계산을 하는지 파악할  수 있다. 하지만 시간이 오래걸릴 수 있으므로 파라미터를 최소화해야한다.

## 6.1 Gradient Descent

![Image](https://github.com/user-attachments/assets/3b0e7df7-fbe8-47bd-8a42-2d600078a4dd){: width="50%", height="50%"}

![Image](https://github.com/user-attachments/assets/704a4240-0adf-42f1-a183-5fd7e0c1f866)

Gradient Descent에서는 우선 W를 임의의 값으로 초기화를 한다.

그리고 Loss와 gradient를 계산한 뒤에 가중치를 gradient의 반대 방향으로 업데이트 한다.

-gradient 방향으로 아주 조금씩 이동을 하고 이것을 반복하면 결국 수렴할 수 있다.

step_size는 Learning rate라고도 하고 한번 이동할 때 얼마나 이동할지를 정하는 것이다. 실제 학습을 할때 직접 정해줘야하는 중요한 하이퍼파라미터이다.

모델 사이즈나 regularization의 강도 등은 잠시 미루고 올바른 learning rate를 정하는 것을 제일 먼저 확인한다고 한다.

Stochastic Gradient Descent(SGD)

![Image](https://github.com/user-attachments/assets/e20e5946-cc1c-4793-8c6d-10689c5ecbfb)

전체 데이터 셋의 gradient와 Loss를 계산하는 것이 아니라 Minibatch라는 작은 트레이닝 샘플 집합으로 나눠서 학습하는 것. (보통 2의 n승; 32 64 128을 사용한다.)

이 작은 minibatch를 이용해서 Loss의 전체 합의 추정치와 실제 gradient 추정치를 계산하는 것이다.

그래서 stochastic하다는 것은 Monte Carlo Method의 값 추정 방식과 유사하다고 할 수있다.

⇒ 임의의 minibatch를 만들어내고, minibatch에서 Loss와 Gradient를 계산한다. 그리고 W를 업데이트 한다. Loss 추정치와 Gradient 추정치를 사용하는 것

---

지금까지 Linear classifier에 대해서 이야기를 했다. 실제 Raw 이미지 픽셀을 입력으로 받는 형식이었다. 이러한 방식, 영상 자체를 입력으로 사용하는 것은 성능이 좋지 않다.

![Image](https://github.com/user-attachments/assets/ae649114-b820-4460-8e0a-58c1c163de32)

극좌표계를 바꿔 적절하게 feature transform을 한다면 복잡하던 데이터를 변환 후에 선형으로 분리가 가능하게 바꿀수 있다. 실제로도 Linear classifier로 분리할 수 있다.

이러한 기법은 문제를 해결하기 위해서 어떤 feature transform이 필요한지를 알아내는 것이다.

이미지의 경우 픽셀들을 극좌표계로 바꾸는 것은 전혀 말이 안되지만 극좌표계로 변환하는 것을 일종의 feature transform이라 생각한다면 말이 된다.

NN이 나오기전 인기있었던 feature representation

- Color Histogram : 이미지가 전체적으로 어떤 색인지 알 수 있다,
- Histogram of Oriented Gradients (HoG) : Local orientation edges를 측정해 이미지가 전반적으로 어떤 종류의 edge정보를 나타내는지 알 수 있다. 또한 이미지를 여러 부분으로 나눠 각 부분에 어떤 edge가 존재하는지도 알 수 있다.
- bag of words(BOW) : NLP에서 영감을 받아, 문장의 여러 단어의 발생 빈도를 세서 feature vector로 사용. 어떤 이미지가 있으면, 이 이미지에서의 visual words의 발생 빈도를 통해 이미지를 인코딩 할 수 있다.

[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}
